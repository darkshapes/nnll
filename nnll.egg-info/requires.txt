accelerate>=1.8.1
aiofiles>=24.1.0
aiohttp>=3.12.13
blake3>=1.0.5
diffusers@ git+https://github.com/huggingface/diffusers.git
gguf>=0.17.1
huggingface-hub[cli,hf-transfer,hf-xet]>=0.33.2
llama-cpp-python>=0.3.9
peft>=0.15.2
pillow>=11.2.1
protobuf>=5.29.5
psutil>=7.0.0
pydantic>=2.11.7
rich>=14.0.0
structlog>=25.4.0
transformers@ git+https://github.com/huggingface/transformers

[:python_version < "3.13"]
sentencepiece

[:python_version >= "3.13"]
sentencepiece@ git+https://github.com/google/sentencepiece.git#subdirectory=python

[:sys_platform != "darwin"]
bitsandbytes>=0.46.0

[:sys_platform != "darwin" and python_version < "3.12"]
nnll[cpu,cu126,rocm]

[:sys_platform != "darwin" and python_version >= "3.12"]
nnll[cpu,cu128,rocm]

[:sys_platform == "darwin"]
nnll[mps]

[attention]

[attention:sys_platform != "darwin"]
sageattention

[attention:sys_platform == "Linux"]
flash_attn

[cpu]
torch
torchvision
torchaudio

[cu126]
torch
torchvision
torchaudio
nnll[triton]

[cu128]
torch
torchvision
torchaudio
nnll[attention,triton]

[dev]
nnll[full]
aioresponses>=0.7.8
pytest>=8.4.1
pytest-asyncio>=1.0.0
pytest-mock>=3.14.1
pytest-tornasync>=0.6.0.post2
pytest-trio>=0.8.0
ruff>=0.12.0

[full]
nnll[cu126,cu128,hidiffusion,lmstudio,mps,ollama,outetts]

[hidiffusion]
hidiffusion>=0.1.10

[lmstudio]
lmstudio>=1.3.1

[mps]
torch
torchvision
torchaudio
mlx-vlm<=0.1.26
mlx-lm<=0.24.1
numpy<=2.2
mflux>=0.2.1
nnll[openai]
pip>=25.0.1

[mps:python_version < "3.13" and sys_platform == "darwin"]
misaki>=0.8.2

[mps:python_version > "3.12" and sys_platform == "darwin"]
misaki[en]@ git+https://github.com/hexgrad/misaki

[mps:sys_platform == "darwin"]
mlx-audio

[ollama]
ollama>=0.5.1

[openai]
openai>=1.84.0

[openai:python_version <= "3.12"]
openai-whisper@ git+https://github.com/openai/whisper.git
llvmlite>=0.36
numba>=0.47.0

[openai:python_version > "3.12"]
openai-whisper@ git+https://github.com/openai/whisper.git
llvmlite>=0.44
numba>=0.61.2

[outetts]
nnll[openai]

[outetts:sys_platform != "darwin"]
outetts

[rocm]
torch
torchvision
torchaudio
pytorch-triton-rocm
nnll[attention]

[triton]

[triton:sys_platform == "Linux"]
triton

[triton:sys_platform == "win32"]
triton-windows
