Metadata-Version: 2.4
Name: nnll
Version: 0.1.dev199+g9af0ccc.d20250322
Summary: Neural Network Link Library : A comprehensive modular toolkit for Diffusion and Large Language Model inference processes.
Author-email: darkshapes <91800957+exdysa@users.noreply.github.com>
License: #// SPDX-License-Identifier: blessing
        The author disclaims copyright to this source code.  In place of
        a legal notice, here is a blessing:
        
          *   May you do good and not evil.
          *   May you find forgiveness for yourself and forgive others.
          *   May you share freely, never taking more than you give.
        
Project-URL: source, https://github.com/darkshapes/nnll
Keywords: ML,AI,neural network,library,diffusion,LLM,torch
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Provides-Extra: nnll-02
Requires-Dist: rich>=13.9.4; extra == "nnll-02"
Provides-Extra: nnll-03
Requires-Dist: aiofiles>=24.1.0; extra == "nnll-03"
Requires-Dist: aiohttp>=3.11.13; extra == "nnll-03"
Requires-Dist: tqdm>=4.67.1; extra == "nnll-03"
Provides-Extra: nnll-05
Requires-Dist: gguf>=0.14.0; extra == "nnll-05"
Requires-Dist: llama-cpp-python>=0.3.8; extra == "nnll-05"
Provides-Extra: nnll-08
Requires-Dist: numpy>=2.2.3; extra == "nnll-08"
Requires-Dist: torch>=2.6.0; extra == "nnll-08"
Provides-Extra: nnll-09
Requires-Dist: torch>=2.6.0; extra == "nnll-09"
Requires-Dist: torchvision>=0.21.0; extra == "nnll-09"
Requires-Dist: transformers>=4.49.0; extra == "nnll-09"
Provides-Extra: nnll-10
Requires-Dist: dspy>=2.6.13; extra == "nnll-10"
Requires-Dist: litellm>=1.63.12; extra == "nnll-10"
Requires-Dist: sounddevice>=0.5.1; extra == "nnll-10"
Requires-Dist: textual>=2.1.2; extra == "nnll-10"
Requires-Dist: textual-plotext>=1.0.1; extra == "nnll-10"
Provides-Extra: nnll-11
Requires-Dist: dspy>=2.6.13; extra == "nnll-11"
Requires-Dist: pydantic>=2.10.6; extra == "nnll-11"
Provides-Extra: nnll-14
Requires-Dist: matplotlib>=3.10.1; extra == "nnll-14"
Requires-Dist: networkx>=3.4.2; extra == "nnll-14"
Requires-Dist: textual>=2.1.2; extra == "nnll-14"
Provides-Extra: nnll-15
Requires-Dist: pydantic>=2.10.6; extra == "nnll-15"
Provides-Extra: nnll-16
Requires-Dist: torch>=2.6.0; extra == "nnll-16"
Provides-Extra: nnll-18
Requires-Dist: torch>=2.6.0; extra == "nnll-18"
Provides-Extra: nnll-26
Requires-Dist: torch>=2.6.0; extra == "nnll-26"
Provides-Extra: nnll-44
Requires-Dist: huggingface-hub>=0.29.1; extra == "nnll-44"
Provides-Extra: nnll-45
Requires-Dist: huggingface-hub>=0.29.1; extra == "nnll-45"
Provides-Extra: nnll-47
Requires-Dist: pydantic>=2.10.6; extra == "nnll-47"
Requires-Dist: pydantic-core>=2.27.2; extra == "nnll-47"
Provides-Extra: nnll-48
Requires-Dist: pillow>=11.1.0; extra == "nnll-48"
Requires-Dist: toml>=0.10.2; extra == "nnll-48"
Provides-Extra: nnll-49
Requires-Dist: pydantic>=2.10.6; extra == "nnll-49"
Provides-Extra: nnll-56
Requires-Dist: hidiffusion>=0.1.10; extra == "nnll-56"
Requires-Dist: torch>=2.6.0; extra == "nnll-56"
Provides-Extra: nnll-57
Requires-Dist: pillow>=11.1.0; extra == "nnll-57"
Provides-Extra: nnll-63
Requires-Dist: diffusers>=0.32.2; extra == "nnll-63"
Requires-Dist: hidiffusion>=0.1.10; extra == "nnll-63"
Requires-Dist: torch>=2.6.0; extra == "nnll-63"
Requires-Dist: torchvision>=0.21.0; extra == "nnll-63"
Provides-Extra: nnll-64
Requires-Dist: pillow>=11.1.0; extra == "nnll-64"
Provides-Extra: all
Requires-Dist: nnll[nnll_02]; extra == "all"
Requires-Dist: nnll[nnll_03]; extra == "all"
Requires-Dist: nnll[nnll_05]; extra == "all"
Requires-Dist: nnll[nnll_09]; extra == "all"
Requires-Dist: nnll[nnll_10]; extra == "all"
Requires-Dist: nnll[nnll_11]; extra == "all"
Requires-Dist: nnll[nnll_14]; extra == "all"
Requires-Dist: nnll[nnll_15]; extra == "all"
Requires-Dist: nnll[nnll_16]; extra == "all"
Requires-Dist: nnll[nnll_26]; extra == "all"
Requires-Dist: nnll[nnll_18]; extra == "all"
Requires-Dist: nnll[nnll_44]; extra == "all"
Requires-Dist: nnll[nnll_45]; extra == "all"
Requires-Dist: nnll[nnll_47]; extra == "all"
Requires-Dist: nnll[nnll_48]; extra == "all"
Requires-Dist: nnll[nnll_49]; extra == "all"
Requires-Dist: nnll[nnll_56]; extra == "all"
Requires-Dist: nnll[nnll_57]; extra == "all"
Requires-Dist: nnll[nnll_63]; extra == "all"
Requires-Dist: nnll[nnll_64]; extra == "all"
Provides-Extra: dev
Requires-Dist: nnll[all]; extra == "dev"
Dynamic: license-file

<div align="center">

![nnll75_transparent](https://github.com/user-attachments/assets/de8c1a49-4695-4c4b-b7c4-29fba483a65d)</div>
# nnll

## neural network link library

`nnll` (or <em>null</em>) is a project incubator and AI toolkit for managing and processing Diffusion and Large Language Models (LLMs). The project is divided into modular, ready-to-use components, and may appeal to researchers or developers working in the general field of machine learning.

Emphasis is on refining and optimizing code for extracting and classifying metadata, ML pipeline preparation, GPU configuration, consumer-grade system optimization, and a comprehensive suite of direct and indirect generative AI preparations for ðŸ§¨Diffusers, ðŸ¤—Transformers, ðŸ¦™Ollama and ðŸŒ€DSPy frameworks.

Thank you for looking forward to it.

<br>

# :shipit:

[![Python application](https://github.com/darkshapes/nnll/actions/workflows/python-app.yml/badge.svg)](https://github.com/darkshapes/nnll/actions/workflows/python-app.yml)<br>
![GitHub repo size](https://img.shields.io/github/repo-size/darkshapes/nnll)<br>
![Discord](https://img.shields.io/discord/1266757128249675867)<br>
<br>

## use
Some modules are full scripts and can be run from command line. These are written here:

`nnll-parse`   - Process metadata headers from a model file or directory of models and write out to individual .json files.<br>
`nnll-find`    - Scan .json files from `-parse` for string patterns within tensor layer metadata and output matches to console.<br>
<br>

## specifics

Each module contains 1-5 functions or 1-2 classes and its own test routines. There are multiple ways to integrate nnll into a project (sorted by level of involvement)

- *Recommended* : Add the project as a dependency including only modules that are needed with `"nnll[nnll_04,nnll_16]" @ git+https://github.com/darkshapes/nnll`
- Install the entire project as a dependency via `nnll @ git+https://github.com/darkshapes/nnll`
- Basic clone or fork of the project
-  Use a [submodule](https://github.blog/open-source/git/working-with-submodules/)
- [Filter](https://github.com/newren/git-filter-repo/) a clone of the project to a single subfolder and include it in your own


`nnll` is a 'living' project. Like a spoken language, it evolves over time. For this reason, we prefer 'living' duplications of the repo. If you still want a static hard copy, you are welcome to copy and paste folders or code wherever you please.

<br><br>

## setup

##### clone repo

> ```
> git clone https://github.com/darkshapes/nnll.git
> ```

<details> <summary> <a>Next--></a></summary>

#####  create virtual environment
> ```
> python3 -m venv .venv_nnll
> ```

<details> <summary> <a>Next--></a></summary>

##### 3 (windows powershell) activate
> ```
> Set-ExecutionPolicy Bypass -Scope Process -Force; .venv_nnll\Scripts\Activate.ps1
> ```

##### 3 ( linux | macos) activate
> ```
> source .venv_nnll/bin/activate
> ```

<details> <summary> <a>Next--></a></summary>

##### 4 install
> ```
> pip install -e nnll
> ```
> or for select packages
> ```
> pip install -e "nnll[nnll_33,nnll_56]"
> ```
> or for all packages :
> ```
> pip install -e "nnll[dev]"
>```

##### Done.
</details>
</details>
</details>
<br><br><br>
