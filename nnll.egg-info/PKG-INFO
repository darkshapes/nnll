Metadata-Version: 2.4
Name: nnll
Version: 0.0.0
Summary: Neural Network Link Library : A comprehensive modular toolkit for Diffusion and Large Language Model inference processes.
Author-email: darkshapes <91800957+exdysa@users.noreply.github.com>
License: #// SPDX-License-Identifier: blessing
        The author disclaims copyright to this source code.  In place of
        a legal notice, here is a blessing:
        
          *   May you do good and not evil.
          *   May you find forgiveness for yourself and forgive others.
          *   May you share freely, never taking more than you give.
        
Project-URL: source, https://github.com/darkshapes/nnll
Keywords: ML,AI,neural network,library,diffusion,LLM,torch
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Provides-Extra: opt
Requires-Dist: ollama; extra == "opt"
Requires-Dist: huggingface-hub; extra == "opt"
Requires-Dist: nnll[18]; extra == "opt"
Requires-Dist: nnll[22]; extra == "opt"
Requires-Dist: nnll[24]; extra == "opt"
Requires-Dist: nnll[25]; extra == "opt"
Requires-Dist: nnll[26]; extra == "opt"
Requires-Dist: nnll[27]; extra == "opt"
Requires-Dist: nnll[28]; extra == "opt"
Requires-Dist: nnll[29]; extra == "opt"
Requires-Dist: nnll[30]; extra == "opt"
Requires-Dist: nnll[31]; extra == "opt"
Requires-Dist: nnll[32]; extra == "opt"
Requires-Dist: nnll[33]; extra == "opt"
Requires-Dist: nnll[34]; extra == "opt"
Requires-Dist: nnll[35]; extra == "opt"
Requires-Dist: nnll[36]; extra == "opt"
Requires-Dist: nnll[37]; extra == "opt"
Requires-Dist: nnll[39]; extra == "opt"
Requires-Dist: nnll[40]; extra == "opt"
Requires-Dist: nnll[41]; extra == "opt"
Requires-Dist: nnll[44]; extra == "opt"
Requires-Dist: nnll[45]; extra == "opt"
Requires-Dist: nnll[46]; extra == "opt"
Requires-Dist: nnll[47]; extra == "opt"
Requires-Dist: nnll[48]; extra == "opt"
Requires-Dist: nnll[49]; extra == "opt"
Requires-Dist: nnll[51]; extra == "opt"
Requires-Dist: nnll[53]; extra == "opt"
Requires-Dist: nnll[54]; extra == "opt"
Requires-Dist: nnll[56]; extra == "opt"
Requires-Dist: nnll[57]; extra == "opt"
Requires-Dist: nnll[59]; extra == "opt"
Requires-Dist: nnll[60]; extra == "opt"
Requires-Dist: nnll[61]; extra == "opt"
Requires-Dist: nnll[62]; extra == "opt"
Requires-Dist: nnll[63]; extra == "opt"
Requires-Dist: nnll[64]; extra == "opt"
Provides-Extra: dev
Requires-Dist: matplotlib>=3.10.1; extra == "dev"
Requires-Dist: nnll[opt]; extra == "dev"
Requires-Dist: pytest>=8.3.4; extra == "dev"
Requires-Dist: pytest-asyncio>=0.25.3; extra == "dev"
Requires-Dist: pytest-tornasync>=0.6.0.post2; extra == "dev"
Requires-Dist: pytest-trio>=0.8.0; extra == "dev"
Requires-Dist: ruff>=0.9.7; extra == "dev"
Requires-Dist: setuptools>=77.0.3; extra == "dev"
Requires-Dist: setuptools-scm>=8.2.1; extra == "dev"
Requires-Dist: textual-dev>=1.7.0; extra == "dev"
Requires-Dist: wheel>=0.45.1; extra == "dev"
Provides-Extra: 09
Requires-Dist: torch>=2.6.0; extra == "09"
Requires-Dist: torchvision>=0.21.0; extra == "09"
Requires-Dist: transformers>=4.49.0; extra == "09"
Provides-Extra: 10
Requires-Dist: dspy>=2.6.13; extra == "10"
Requires-Dist: litellm>=1.63.12; extra == "10"
Requires-Dist: sounddevice>=0.5.1; extra == "10"
Requires-Dist: textual>=2.1.2; extra == "10"
Requires-Dist: textual-plotext>=1.0.1; extra == "10"
Provides-Extra: 11
Requires-Dist: dspy>=2.6.13; extra == "11"
Requires-Dist: pydantic>=2.10.6; extra == "11"
Provides-Extra: 14
Requires-Dist: networkx>=3.4.2; extra == "14"
Requires-Dist: textual>=2.1.2; extra == "14"
Provides-Extra: 15
Requires-Dist: pydantic>=2.10.6; extra == "15"
Provides-Extra: 16
Requires-Dist: torch>=2.6.0; extra == "16"
Provides-Extra: 18
Requires-Dist: torch>=2.6.0; extra == "18"
Provides-Extra: 26
Requires-Dist: torch>=2.6.0; extra == "26"
Provides-Extra: 44
Requires-Dist: huggingface-hub>=0.29.1; extra == "44"
Provides-Extra: 45
Requires-Dist: huggingface-hub>=0.29.1; extra == "45"
Provides-Extra: 47
Requires-Dist: pydantic>=2.10.6; extra == "47"
Requires-Dist: pydantic-core>=2.27.2; extra == "47"
Provides-Extra: 48
Requires-Dist: pillow>=11.1.0; extra == "48"
Requires-Dist: toml>=0.10.2; extra == "48"
Provides-Extra: 49
Requires-Dist: pydantic>=2.10.6; extra == "49"
Provides-Extra: 56
Requires-Dist: hidiffusion>=0.1.10; extra == "56"
Requires-Dist: torch>=2.6.0; extra == "56"
Provides-Extra: 57
Requires-Dist: pillow>=11.1.0; extra == "57"
Provides-Extra: 63
Requires-Dist: diffusers>=0.32.2; extra == "63"
Requires-Dist: hidiffusion>=0.1.10; extra == "63"
Requires-Dist: torch>=2.6.0; extra == "63"
Requires-Dist: torchvision>=0.21.0; extra == "63"
Provides-Extra: 64
Requires-Dist: pillow>=11.1.0; extra == "64"
Dynamic: license-file

<div align="center">

![nnll75_transparent](https://github.com/user-attachments/assets/de8c1a49-4695-4c4b-b7c4-29fba483a65d)</div>
# nnll

## neural network link library
`nnll` (or <em>null</em>) is a comprehensive AI toolkit for managing and processing Diffusion and Large Language Models (LLMs). The project is divided into highly modular, ready-to-use components, and may appeal to researchers or developers working in the general field of machine learning.

Library compatibility includes ðŸ§¨Diffusers, ðŸ¤—Transformers, ðŸ¦™Ollama, and focuses on refining methods for tasks such as extracting and classifying metadata, pipeline preparation, GPU configuration, consumer-grade system optimization, and a variety of direct and indirect generative AI preparations.
<br>

# :shipit:

[![Python application](https://github.com/darkshapes/nnll/actions/workflows/python-app.yml/badge.svg)](https://github.com/darkshapes/nnll/actions/workflows/python-app.yml)<br>
![GitHub repo size](https://img.shields.io/github/repo-size/darkshapes/nnll)<br>
![Discord](https://img.shields.io/discord/1266757128249675867)<br>
<br>

## use
Some modules are full scripts and can be run from command line. These are written here:

`nnll-parse`   - Process metadata headers from a model file or directory of models and write out to individual .json files.<br>
`nnll-find`    - Scan .json files from `-parse` for string patterns within tensor layer metadata and output matches to console.<br>
<br>

## specifics

Each module contains 1-5 functions or 1-2 classes and its own test routines. There are multiple ways to integrate nnll into a project (sorted by level of involvement)

- *Recommended* : Install the project as a dependency via `nnll @ git+https://github.com/darkshapes/nnll`
- Install the entire project as a dependency via `nnll @ git+https://github.com/darkshapes/nnll`
- Basic clone or fork of the project
-  Use a [submodule](https://github.blog/open-source/git/working-with-submodules/)
- [Filter](https://github.com/newren/git-filter-repo/) a clone of the project to a single subfolder and include it in your own


`nnll` is a 'living' project. Like a spoken language, it evolves over time. For this reason, we prefer 'living' duplications of the repo. If you still want a static hard copy, you are welcome to copy and paste folders or code wherever you please.

<br><br>

## setup

##### clone repo

> ```
> git clone https://github.com/darkshapes/nnll.git
> ```

<details> <summary> <a>Next--></a></summary>

#####  create virtual environment
> ```
> python3 -m venv .venv_nnll
> ```

<details> <summary> <a>Next--></a></summary>

##### 3 (windows powershell) activate
> ```
> Set-ExecutionPolicy Bypass -Scope Process -Force; .venv_nnll\Scripts\Activate.ps1
> ```

##### 3 ( linux | macos) activate
> ```
> source .venv_nnll/bin/activate
> ```

<details> <summary> <a>Next--></a></summary>

##### 4 install
> ```
> pip install -e nnll
> ```
or
>
> pip install -e 'nnll\[dev\]'
>

##### Done.
</details>
</details>
</details>
<br><br><br>
