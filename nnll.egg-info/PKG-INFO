Metadata-Version: 2.4
Name: nnll
Version: 0.1.dev230+g101dbf8.d20250402
Summary: Neural Network Link Library : A comprehensive modular toolkit for Diffusion and Large Language Model inference processes.
Author-email: darkshapes <91800957+exdysa@users.noreply.github.com>
License: #// SPDX-License-Identifier: blessing
        The author disclaims copyright to this source code.  In place of
        a legal notice, here is a blessing:
        
          *   May you do good and not evil.
          *   May you find forgiveness for yourself and forgive others.
          *   May you share freely, never taking more than you give.
        
Project-URL: source, https://github.com/darkshapes/nnll
Keywords: ML,AI,neural network,library,diffusion,LLM,torch
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: structlog>=25.2.0
Provides-Extra: nnll-02
Requires-Dist: huggingface-hub>=0.29.3; extra == "nnll-02"
Requires-Dist: litellm>=1.65.0; extra == "nnll-02"
Provides-Extra: nnll-03
Requires-Dist: aiofiles>=24.1.0; extra == "nnll-03"
Requires-Dist: aiohttp<=3.11.13,>=3.9.5; extra == "nnll-03"
Requires-Dist: tqdm>=4.67.1; extra == "nnll-03"
Provides-Extra: nnll-04
Requires-Dist: gguf>=0.14.0; extra == "nnll-04"
Requires-Dist: llama-cpp-python>=0.3.8; extra == "nnll-04"
Provides-Extra: nnll-05
Requires-Dist: networkx>=3.4.2; extra == "nnll-05"
Provides-Extra: nnll-06
Requires-Dist: litellm>=1.65.0; extra == "nnll-06"
Requires-Dist: ollama>=0.4.7; extra == "nnll-06"
Requires-Dist: tiktoken>=0.9.0; extra == "nnll-06"
Provides-Extra: nnll-08
Requires-Dist: numpy>=2.2.3; extra == "nnll-08"
Requires-Dist: torch>=2.6.0; extra == "nnll-08"
Provides-Extra: nnll-09
Requires-Dist: torch>=2.6.0; extra == "nnll-09"
Requires-Dist: torchvision>=0.21.0; extra == "nnll-09"
Requires-Dist: transformers>=4.49.0; extra == "nnll-09"
Provides-Extra: nnll-10
Requires-Dist: rich>=13.9.4; extra == "nnll-10"
Requires-Dist: dspy>=2.6.13; extra == "nnll-10"
Requires-Dist: sounddevice>=0.5.1; extra == "nnll-10"
Requires-Dist: textual[syntax]>=2.1.2; extra == "nnll-10"
Requires-Dist: textual-plotext>=1.0.1; extra == "nnll-10"
Requires-Dist: ollama>=0.4.7; extra == "nnll-10"
Requires-Dist: numpy>=2.2.3; extra == "nnll-10"
Requires-Dist: tree-sitter>=0.24.0; extra == "nnll-10"
Requires-Dist: litellm>=1.65.0; extra == "nnll-10"
Provides-Extra: nnll-11
Requires-Dist: dspy>=2.6.13; extra == "nnll-11"
Requires-Dist: pydantic>=2.10.6; extra == "nnll-11"
Provides-Extra: nnll-12
Requires-Dist: textual[syntax]>=2.1.2; extra == "nnll-12"
Requires-Dist: networkx>=3.4.2; extra == "nnll-12"
Requires-Dist: tree-sitter>=0.24.0; extra == "nnll-12"
Provides-Extra: nnll-13
Requires-Dist: sounddevice>=0.5.1; extra == "nnll-13"
Requires-Dist: textual-plotext>=1.0.1; extra == "nnll-13"
Provides-Extra: nnll-14
Requires-Dist: matplotlib>=3.10.1; extra == "nnll-14"
Requires-Dist: networkx>=3.4.2; extra == "nnll-14"
Requires-Dist: textual>=2.1.2; extra == "nnll-14"
Requires-Dist: tree-sitter>=0.24.0; extra == "nnll-14"
Provides-Extra: nnll-15
Requires-Dist: huggingface-hub[hf-transfer]>=0.29.1; extra == "nnll-15"
Requires-Dist: ollama>=0.4.7; extra == "nnll-15"
Requires-Dist: pydantic>=2.10.6; extra == "nnll-15"
Provides-Extra: nnll-16
Requires-Dist: torch>=2.6.0; extra == "nnll-16"
Provides-Extra: nnll-18
Requires-Dist: torch>=2.6.0; extra == "nnll-18"
Provides-Extra: nnll-26
Requires-Dist: torch>=2.6.0; extra == "nnll-26"
Provides-Extra: nnll-36
Requires-Dist: torch>=2.6.0; extra == "nnll-36"
Provides-Extra: nnll-44
Requires-Dist: huggingface-hub[hf-transfer]>=0.29.1; extra == "nnll-44"
Provides-Extra: nnll-45
Requires-Dist: huggingface-hub[hf-transfer]>=0.29.1; extra == "nnll-45"
Provides-Extra: nnll-47
Requires-Dist: pydantic>=2.10.6; extra == "nnll-47"
Requires-Dist: pydantic-core>=2.27.2; extra == "nnll-47"
Provides-Extra: nnll-48
Requires-Dist: pillow>=11.1.0; extra == "nnll-48"
Requires-Dist: toml>=0.10.2; extra == "nnll-48"
Provides-Extra: nnll-49
Requires-Dist: pydantic>=2.10.6; extra == "nnll-49"
Provides-Extra: nnll-56
Requires-Dist: hidiffusion>=0.1.10; extra == "nnll-56"
Requires-Dist: torch>=2.6.0; extra == "nnll-56"
Requires-Dist: torchvision>=0.21.0; extra == "nnll-56"
Provides-Extra: nnll-62
Requires-Dist: diffusers>=0.32.2; extra == "nnll-62"
Requires-Dist: torch>=2.6.0; extra == "nnll-62"
Requires-Dist: torchvision>=0.21.0; extra == "nnll-62"
Provides-Extra: nnll-64
Requires-Dist: pillow>=11.1.0; extra == "nnll-64"
Provides-Extra: all
Requires-Dist: nnll[nnll_02]; extra == "all"
Requires-Dist: nnll[nnll_03]; extra == "all"
Requires-Dist: nnll[nnll_04]; extra == "all"
Requires-Dist: nnll[nnll_05]; extra == "all"
Requires-Dist: nnll[nnll_06]; extra == "all"
Requires-Dist: nnll[nnll_08]; extra == "all"
Requires-Dist: nnll[nnll_09]; extra == "all"
Requires-Dist: nnll[nnll_10]; extra == "all"
Requires-Dist: nnll[nnll_11]; extra == "all"
Requires-Dist: nnll[nnll_12]; extra == "all"
Requires-Dist: nnll[nnll_13]; extra == "all"
Requires-Dist: nnll[nnll_14]; extra == "all"
Requires-Dist: nnll[nnll_15]; extra == "all"
Requires-Dist: nnll[nnll_16]; extra == "all"
Requires-Dist: nnll[nnll_18]; extra == "all"
Requires-Dist: nnll[nnll_26]; extra == "all"
Requires-Dist: nnll[nnll_36]; extra == "all"
Requires-Dist: nnll[nnll_44]; extra == "all"
Requires-Dist: nnll[nnll_45]; extra == "all"
Requires-Dist: nnll[nnll_47]; extra == "all"
Requires-Dist: nnll[nnll_48]; extra == "all"
Requires-Dist: nnll[nnll_49]; extra == "all"
Requires-Dist: nnll[nnll_56]; extra == "all"
Requires-Dist: nnll[nnll_62]; extra == "all"
Requires-Dist: nnll[nnll_64]; extra == "all"
Provides-Extra: dev
Requires-Dist: nnll[all]; extra == "dev"
Requires-Dist: aioresponses>=0.7.8; extra == "dev"
Requires-Dist: pytest-asyncio>=0.25.3; extra == "dev"
Requires-Dist: pytest>=8.3.4; extra == "dev"
Requires-Dist: ruff>=0.9.7; extra == "dev"
Requires-Dist: textual-dev>=1.7.0; extra == "dev"
Requires-Dist: pytest-tornasync>=0.6.0.post2; extra == "dev"
Requires-Dist: pytest-trio>=0.8.0; extra == "dev"
Requires-Dist: viztracer>=1.0.3; extra == "dev"
Dynamic: license-file

<div align="center">

![nnll75_transparent](https://github.com/user-attachments/assets/de8c1a49-4695-4c4b-b7c4-29fba483a65d)</div>
# nnll <br><sub>neural network link library</sub>

`nnll` (or <em>null</em>) is a project incubator and AI toolkit for managing and processing Diffusion and Large Language Models (LLMs). The project is divided into modular, ready-to-use components and may appeal to researchers or developers working in the general field of machine learning.

* Generative AI pipeline preparation & execution
* Extracting and classifying metadata from images/models
* Consumer-grade GPU/CPU inference optimization
* Misc UX/UI Experimentation
* üß®Diffusers, ü§óTransformers, ü¶ôOllama, üçèMLX, üåÄDSPy, üöÖLiteLLM<br><br>

# :shipit:
[![Python application test status](https://github.com/darkshapes/nnll/actions/workflows/python-app.yml/badge.svg)](https://github.com/darkshapes/nnll/actions/workflows/python-app.yml) <br>
![commits per month](https://img.shields.io/github/commit-activity/m/darkshapes/nnll?color=indigo)<br>
![code size](https://img.shields.io/github/languages/code-size/darkshapes/nnll?color=navy)<br>
![Discord](https://img.shields.io/discord/1266757128249675867?color=black)<br><br>

## setup <br> <sub>`clone` -> `venv` -> `activate` -> `pip install "nnll[module]"`<sub>
#####  clone repo
> ```
> git clone https://github.com/darkshapes/nnll.git
> ```

<details> <summary> <a>Next--></a></summary>

#####  create virtual environment
> ```
> python3 -m venv .venv_nnll
> ```

<details> <summary> <a>Next--></a></summary>

##### 3 (windows powershell) activate
> ```
> Set-ExecutionPolicy Bypass -Scope Process -Force; .venv_nnll\Scripts\Activate.ps1
> ```

##### 3 ( linux | macos) activate
> ```
> source .venv_nnll/bin/activate
> ```

<details> <summary> <a>Next--></a></summary>

##### 4 install
> - install the bare minimum:
> ```
> pip install -e nnll
> ```
> - install select packages:
> ```
> pip install -e "nnll[nnll_33,nnll_56]"
> ```
> - install all packages :
> ```
> pip install -e "nnll[dev]"
>```
##### Done.
</details></details></details><br>

## use
Some modules are full scripts and can be run from command line. These are written here:

`astra`        - Experimental generative system<br>
`nnll-parse`   - Process metadata headers from a model file or directory of models and write out to individual .json files.<br>
<br>

Each module contains 1-5 functions or 1-2 classes and its own test routines. There are multiple ways to integrate nnll into a project (sorted by level of involvement)

- *Recommended* : Add the project as a dependency including only modules that are needed with `"nnll[nnll_04,nnll_16]" @ git+https://github.com/darkshapes/nnll`
- Install the entire project as a dependency via `nnll @ git+https://github.com/darkshapes/nnll`
- Basic clone or fork of the project
-  Use a [submodule](https://github.blog/open-source/git/working-with-submodules/)
- [Filter](https://github.com/newren/git-filter-repo/) a clone of the project to a single subfolder and include it in your own


`nnll` is a 'living' project. Like a spoken language, it evolves over time. For this reason, we prefer 'living' duplications of the repo. If you still want a static hard copy, you are welcome to copy and paste folders or code wherever you please.<br><br>
## contributing
```
* Environment  : uv
* Testing      : pytest -vv tests/*.py
* Formatting   : ruff/better align
* Linting      : ruff/pylint
* Type Checking: pylance/pyright
* Spelling     : typos vsc
```
<br>

![Alt](https://repobeats.axiom.co/api/embed/13fd2c53953a777ae8583f620fa8bd014baadef1.svg "Repobeats analytics image")
