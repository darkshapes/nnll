# SPDX-License-Identifier: MPL-2.0 AND LicenseRef-Commons-Clause-License-Condition-1.0
# <!-- // /*  d a r k s h a p e s */ -->

[build-system]
requires      = ["setuptools", "setuptools_scm"]
build-backend = "setuptools.build_meta"

[project]
authors = [
    { name = "darkshapes", email = "91800957+exdysa@users.noreply.github.com" },
]
description = "Neural Network Link Library : A comprehensive modular toolkit for Diffusion and Large Language Model inference processes."
dynamic = ["version"]
name = "nnll"
readme = "README.md"
requires-python = ">= 3.11"
keywords = [
    "AI",
    "neural network",
    "library",
    "Diffusion",
    "LLM",
    "identification",
    "URI",
]
classifiers = [
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Intended Audience :: Developers",
    "Intended Audience :: Information Technology",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
    "Operating System :: OS Independent",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Scientific/Engineering :: Image Processing",
    "Topic :: Multimedia",
    "Topic :: Multimedia :: Graphics",
    "Topic :: Multimedia :: Graphics :: Editors",
    "Topic :: Multimedia :: Graphics :: Graphics Conversion",
    "Topic :: Multimedia :: Graphics :: Presentation",
    "Topic :: Multimedia :: Graphics :: Viewers",
    "Topic :: Multimedia :: Sound/Audio",
    "Topic :: Multimedia :: Sound/Audio :: Conversion",
    "Topic :: Multimedia :: Sound/Audio :: Editors",
    "Topic :: Multimedia :: Sound/Audio :: Mixers",
    "Topic :: Multimedia :: Sound/Audio :: Players",
    "Topic :: Multimedia :: Video",
    "Topic :: Multimedia :: Video :: Capture",
    "Topic :: Multimedia :: Video :: Conversion",
    "Topic :: Multimedia :: Video :: Display",
    "Topic :: Multimedia :: Video :: Non-Linear Editor",
]
dependencies = [
    "nnll[cu126,cpu,torch]; sys_platform == 'win32' and python_version < '3.13'",
    "nnll[cu128,cpu,torch]; sys_platform == 'win32' and python_version > '3.12' ",
    "nnll[cu126,rocm,cpu,torch]; sys_platform == 'linux' and python_version < '3.13'",
    "nnll[cu128,rocm,cpu,torch]; sys_platform == 'linux' and python_version > '3.12' ",
    "nnll[mps]; sys_platform == 'darwin'",
    #gguf
    "gguf>=0.17.1",
    "llama-cpp-python>=0.3.16",
    "bitsandbytes>=0.46.0 ; sys_platform != 'darwin'",
    #diffusers
    "diffusers>=0.34.0",
    "accelerate>=1.10.0",
    "peft>=0.17.0",
    #async
    "aiohttp>=3.12.15",
    "aiofiles>=24.1.0",
    "blake3>=1.0.5",
    "structlog>=25.4.0",
    "huggingface-hub[cli,hf-transfer,hf-xet]>=0.35.0rc0",
]
[dependency-groups]
full = ["nnll[cu126,cu128,mps,rocm,torch,jax,onnx,ollama,openai,vllm,lmstudio]"]
dev = [
    "nnll[full]",
    "diffusers @ git+https://github.com/huggingface/diffusers.git",
    "transformers @ git+https://github.com/huggingface/transformers.git",
    "aioresponses>=0.7.8",
    "pytest>=8.4.1",
    "pytest-asyncio>=1.1.0",
    "pytest-mock>=3.14.1",
    "pytest-tornasync>=0.6.0.post2",
    "pytest-trio>=0.8.0",
    "ruff>=0.12.9",
]

torch = ["torch", "torchvision", "torchaudio", "torchsde"]
[project.optional-dependencies]
# -- frameworks --
torch = ["torch", "torchvision", "torchaudio", "torchsde"]
onnx  = ["onnx>=1.18.0"]
jax   = ["flax>=0.10.7", "jax>=0.6.2"]

mps = [
    "nnll[openai]",
    "mlx-vlm<=0.1.26 ; sys_platform == 'darwin'",                                                                 # all specifc due to mlx-audio
    "mlx-lm<=0.24.1 ; sys_platform == 'darwin'",                                                                  # ...
    "mlx-audio; sys_platform == 'darwin'",                                                                        # ... etc
    "numpy<=2.2; sys_platform == 'darwin'",
    "misaki>=0.8.2 ; python_version < '3.13' and sys_platform == 'darwin'",
    "misaki[en] @ git+https://github.com/hexgrad/misaki ; python_version >= '3.13' and sys_platform == 'darwin'",
    "pip>=25.0.1",                                                                                                # chroma",
    "mflux>=0.2.1 ; sys_platform == 'darwin'",
    # flux
] # -- accelerators --

cu126 = ["nnll[triton]"]
cu128 = ["nnll[triton,attention]"]
rocm  = ["pytorch-triton-rocm ; sys_platform == 'Linux'", "nnll[attention]"]

# -- efficiency --
attention = [
    "sageattention; sys_platform != 'darwin'",
    "flash_attn ; sys_platform == 'Linux'",
]
triton = [
    "triton ; sys_platform == 'Linux'",
    "triton-windows ; sys_platform == 'win32'",
]

# -- providers --
ollama   = ["ollama>=0.5.1"]
lmstudio = ["lmstudio>=1.3.1"]
vllm     = ["vllm>=0.9.0.1 ; sys_platform == 'Linux'"]

openai = [
    "openai>=1.84.0",
    "openai-whisper @ git+https://github.com/openai/whisper.git",
    "llvmlite>=0.44 ; python_version > '3.12'",
    "llvmlite>=0.36 ; python_version < '3.13'",
    "numba>=0.61.2 ; python_version > '3.12'",
    "numba>=0.47.0 ; python_version < '3.13'",
]
outetts = ["nnll[openai]", "outetts ; sys_platform != 'darwin'"]

full = ["nnll[cu126,cu128,mps,rocm,torch,jax,onnx,ollama,openai,vllm,lmstudio]"]
dev = [
    "nnll[full]",
    "diffusers @ git+https://github.com/huggingface/diffusers.git",
    "transformers @ git+https://github.com/huggingface/transformers.git",
    "aioresponses>=0.7.8",
    "pytest>=8.4.1",
    "pytest-asyncio>=1.1.0",
    "pytest-mock>=3.14.1",
    "pytest-tornasync>=0.6.0.post2",
    "pytest-trio>=0.8.0",
    "ruff>=0.12.9",
]

# probably should be installed by sdbx
# audiocraft = [
# "audiocraft @ git+https://github.com/exdysa/facebookresearch-audiocraft-revamp.git@x/dev",
# ]
# bagel = ["bagel @ git+https://github.com/exdysa/ByteDance-Bagel.git"]
# chroma = ["mlx-chroma @ git+https://github.com/exdysa/jack813-mlx-chroma.git"]
# "hidiffusion>=0.1.10",
# orpheus_tts = ["orpheus_tts @ git+https://github.com/canopyai/Orpheus-TTS.git"]
# parler_tts = ["parler-tts @ git+https://github.com/huggingface/parler-tts.git"]
# xllmx = ["xllmx @ git+https://github.com/Alpha-VLLM/Lumina-mGPT"]
# tts = [ "nnll[audiocraft, bagel, parler_tts]", "nnll[audiocraft, bagel, parler_tts] ; platform_system != 'darwin'",]


[project.urls]
Homepage      = "https://github.com/darkshapes/nnll"
Documentation = "https://github.com/darkshapes/sdbx/wiki"

[project.scripts]
mir-add       = "nnll.mir.mir:main"
mir-autopipe  = "nnll.download.autopipe:main"
mir-maid      = "nnll.mir.maid:main"
mir-tasks     = "nnll.model_detect.tasks:main"
mir-pipe      = "nnll.model_detect.tasks:pipe"
nnll-autocard = "nnll.metadata.autocard:main"
nnll-autohash = "nnll.download.hub_cache:main"
nnll-hash     = "nnll.integrity.hash_256:main"
nnll-info     = "nnll.configure.chip_stats:main"
nnll-layer    = "nnll.model_detect.layer_compare:main"
nnll-meta     = "nnll.metadata.model_tags:main"

[tool.uv]
preview = true
prerelease = "allow"
conflicts = [
    [
        { extra = "mlx" },
        { extra = "cpu" },
        { extra = "mps" },
        { extra = "cu126" },
        { extra = "cu128" },
        { extra = "rocm" },
        { extra = "attention" },
        # { extra = "torch" },
        # { extra = "triton" },
        # { extra = "hidiffusion" },
        # { extra = "lmstudio" },
        # { extra = "ollama" },
        # { extra = "outetts" },
        # { extra = "onnx" },
        # { extra = "jax" },
    ],
]

# [tool.uv.pip] # ignore: even-better-toml
# torch-backend = "auto"

[[tool.uv.index]]
name     = "pytorch-cpu"
url      = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name     = "pytorch-nightly"
url      = "https://download.pytorch.org/whl/nightly/cpu"
explicit = true

[[tool.uv.index]]
name     = "pytorch-cu126"
url      = "https://download.pytorch.org/whl/cu126"
explicit = true

[[tool.uv.index]]
name     = "pytorch-cu128"
url      = "https://download.pytorch.org/whl/cu128"
explicit = true

[[tool.uv.index]]
name     = "pytorch-rocm"
url      = "https://download.pytorch.org/whl/rocm6.3"
explicit = true

torch = [
    { index = "pytorch-cpu", extra = "cpu", marker = "sys_platform != 'darwin'" },
    { index = "pytorch-nightly", group = "mps", extra = "mps", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cu126", extra = "cu126", marker = "sys_platform == 'Linux' or sys_platform == 'win32'" },
    { index = "pytorch-cu128", extra = "cu128", marker = "sys_platform == 'Linux' or sys_platform == 'win32'" },
    { index = "pytorch-rocm", extra = "rocm", marker = "sys_platform == 'Linux'" },
]
torchvision = [
    { index = "pytorch-cpu", extra = "cpu", marker = "sys_platform != 'darwin'" },
    { index = "pytorch-nightly", extra = "mps", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cu126", extra = "cu126", marker = "sys_platform == 'Linux' or sys_platform == 'win32'" },
    { index = "pytorch-cu128", extra = "cu128", marker = "sys_platform == 'Linux' or sys_platform == 'win32'" },
    { index = "pytorch-rocm", extra = "rocm", marker = "sys_platform == 'Linux'" },
]
torchaudio = [
    { index = "pytorch-cpu", extra = "cpu", marker = "sys_platform != 'darwin'" },
    { index = "pytorch-nightly", extra = "mps", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cu126", extra = "cu126", marker = "sys_platform == 'Linux' or sys_platform == 'win32'" },
    { index = "pytorch-cu128", extra = "cu128", marker = "sys_platform == 'Linux' or sys_platform == 'win32'" },
    { index = "pytorch-rocm", extra = "rocm", marker = "sys_platform == 'Linux'" },
]

[tool.setuptools_scm]
write_to = "_version.py"

[tool.setuptools.packages.find]
where   = ["."]
include = ["nnll*"]
exclude = ["tests*"]

[tool.setuptools.package-data]
nnll = ['nnll/integrity/*.json', "nnll/mir/config/*.json"]

[tool.ruff]
line-length    = 140
include        = ["*.py"]
extend-exclude = ["^tests/.*$", "test.*$"]

[tool.ruff.lint]
ignore = ["E731"]

[tool.pylint]
max-line-length = 140
ignore-paths    = ["^tests/.*$", "test_.*$"]
disable         = ["C0415"]

[tool.ruff.lint.pycodestyle]
max-line-length               = 140
ignore-overlong-task-comments = true

[tool.typos]
files.extend-exclude = ["^tests/.*$", "test.*$"]
default.extend-words = { "ot" = "ot", "convers" = "convers" }
