# SPDX-License-Identifier: MPL-2.0 AND LicenseRef-Commons-Clause-License-Condition-1.0
# <!-- // /*  d a r k s h a p e s */ -->

[build-system]
requires      = ["setuptools", "setuptools_scm"]
build-backend = "setuptools.build_meta"

[project]
authors = [
    { name = "darkshapes", email = "91800957+exdysa@users.noreply.github.com" },
]
description = "Neural Network Link Library : A comprehensive modular toolkit for Diffusion and Large Language Model inference processes."
dynamic = ["version"]
name = "nnll"
readme = "README.md"
requires-python = ">= 3.11"
keywords = [
    "AI",
    "neural network",
    "library",
    "Diffusion",
    "LLM",
    "identification",
    "URI",
]
classifiers = [
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Intended Audience :: Developers",
    "Intended Audience :: Information Technology",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
    "Operating System :: OS Independent",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Scientific/Engineering :: Image Processing",
    "Topic :: Multimedia",
    "Topic :: Multimedia :: Graphics",
    "Topic :: Multimedia :: Graphics :: Editors",
    "Topic :: Multimedia :: Graphics :: Graphics Conversion",
    "Topic :: Multimedia :: Graphics :: Presentation",
    "Topic :: Multimedia :: Graphics :: Viewers",
    "Topic :: Multimedia :: Sound/Audio",
    "Topic :: Multimedia :: Sound/Audio :: Conversion",
    "Topic :: Multimedia :: Sound/Audio :: Editors",
    "Topic :: Multimedia :: Sound/Audio :: Mixers",
    "Topic :: Multimedia :: Sound/Audio :: Players",
    "Topic :: Multimedia :: Video",
    "Topic :: Multimedia :: Video :: Capture",
    "Topic :: Multimedia :: Video :: Conversion",
    "Topic :: Multimedia :: Video :: Display",
    "Topic :: Multimedia :: Video :: Non-Linear Editor",
]
dependencies = [
    #basic
    "rich>=14.1.0",
    "structlog>=25.4.0",

    #gguf
    "gguf>=0.17.1",
    "llama-cpp-python>=0.3.16",
    "bitsandbytes>=0.46.0 ; sys_platform != 'darwin'",

    #diffusers
    "diffusers @ git+https://github.com/huggingface/diffusers.git",
    "huggingface-hub[cli,hf-transfer,hf-xet]>=0.35.0rc0",
    "transformers>=4.55.2",
    "accelerate>=1.10.0",
    "peft>=0.17.0",

    #async
    "aiohttp>=3.12.15",
    "aiofiles>=24.1.0",
    "blake3>=1.0.5",
    "ftfy>=6.3.1",
]
[dependency-groups]
dev = [
    "aioresponses>=0.7.8",
    "pytest>=8.4.1",
    "pytest-asyncio>=1.1.0",
    "pytest-mock>=3.14.1",
    "pytest-tornasync>=0.6.0.post2",
    "pytest-trio>=0.8.0",
    "ruff>=0.12.9",
]
[project.optional-dependencies]
# -- frameworks --
onnx = ["onnx>=1.18.0"]
jax  = ["flax>=0.10.7", "jax>=0.6.2"]


# -- accelerators --
cuda = [
    "torch>=2.8",
    "torchvision",
    "torchaudio",
    "torchsde",
    "triton ; sys_platform != 'win32' and sys_platform != 'darwin'",
    "triton-windows ; sys_platform == 'win32'",
    "nnll[jax,onnx,ollama,openai,lmstudio]",
]
#cu128
cpu = ["torch>=2.8", "torchvision", "torchaudio", "torchsde"]
xpu = [
    "torch>=2.8",                                       # entries duplicated (unfortunately) for indexes to work
    "torchvision",
    "torchaudio",
    "torchsde",
    "pytorch-triton-xpu ; platform_machine == 'AMD64'",
    "nnll[jax,onnx,ollama,openai,lmstudio]",

]
mps = [
    "torch>=2.8",
    "torchvision",
    "torchaudio",
    "torchsde",
    "mlx-vlm<=0.1.26 ; sys_platform == 'darwin'",                                                                 # all specifc due to mlx-audio
    "mlx-lm<=0.24.1 ; sys_platform == 'darwin'",                                                                  # ...
    "mlx-audio; sys_platform == 'darwin'",                                                                        # ... etc
    "numpy<=2.2; sys_platform == 'darwin'",
    "misaki>=0.8.2 ; python_version < '3.13' and sys_platform == 'darwin'",
    "misaki[en] @ git+https://github.com/hexgrad/misaki ; python_version >= '3.13' and sys_platform == 'darwin'",
    "pip>=25.0.1",                                                                                                # chroma",
    "mflux>=0.2.1 ; sys_platform == 'darwin'",
    "nnll[jax,onnx,ollama,openai,lmstudio]",
]
rocm = [
    "torch>=2.8",
    "torchvision",
    "torchaudio",
    "torchsde",
    "flash_attn ; sys_platform == 'Linux'",
    "pytorch-triton-rocm ; sys_platform == 'Linux'",
    "nnll[jax,onnx,ollama,openai,lmstudio,attention]",
]

# -- mem efficiency --
attention = ["sageattention; sys_platform != 'darwin'"]

# -- providers --
ollama   = ["ollama>=0.5.1"]
lmstudio = ["lmstudio>=1.3.1"]

openai = [
    "openai>=1.84.0",
    "openai-whisper @ git+https://github.com/openai/whisper.git",
    "llvmlite>=0.44 ; python_version > '3.12'",
    "llvmlite>=0.36 ; python_version < '3.13'",
    "numba>=0.61.2 ; python_version > '3.12'",
    "numba>=0.47.0 ; python_version < '3.13'",
]
outetts = ["nnll[openai]", "outetts ; sys_platform != 'darwin'"]
dev = [
    "nnll[full]",
    "aioresponses>=0.7.8",
    "pytest>=8.4.1",
    "pytest-asyncio>=1.1.0",
    "pytest-mock>=3.14.1",
    "pytest-tornasync>=0.6.0.post2",
    "pytest-trio>=0.8.0",
    "ruff>=0.12.9",
]
full = [
    "nnll[mps] ; sys_platform == 'darwin'",
    "nnll[cuda] ; sys_platform != 'darwin'",
]

[project.urls]
Homepage      = "https://github.com/darkshapes/nnll"
Documentation = "https://github.com/darkshapes/sdbx/wiki"

[project.scripts]
mir-add       = "nnll.mir.mir:main"
mir-autopipe  = "nnll.download.autopipe:main"
mir-maid      = "nnll.mir.maid:main"
mir-tasks     = "nnll.model_detect.tasks:main"
mir-pipe      = "nnll.model_detect.tasks:pipe"
nnll-autocard = "nnll.metadata.autocard:main"
nnll-autohash = "nnll.download.hub_cache:main"
nnll-hash     = "nnll.integrity.hash_256:main"
nnll-info     = "nnll.configure.chip_stats:main"
nnll-layer    = "nnll.model_detect.layer_compare:main"
nnll-meta     = "nnll.metadata.model_tags:main"


[tool.uv]
dev-dependencies = ["nnll[dev]"]
prerelease       = "allow"
preview          = true

conflicts = [
    [
        { extra = "mps" },
        { extra = "cuda" },
        { extra = "xpu" },
        { extra = "rocm" },
        { extra = "triton" },
    ],
]
no-build-isolation-package = ["sageattention", "flash_attn"]

[[tool.uv.index]]
name     = "pytorch-cpu"
url      = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name     = "pytorch-cu128"
url      = "https://download.pytorch.org/whl/cu128"
explicit = true

[[tool.uv.index]]
name     = "pytorch-rocm"
url      = "https://download.pytorch.org/whl/rocm6.3"
explicit = true

[[tool.uv.index]]
name     = "pytorch-xpu"
url      = "https://download.pytorch.org/whl/xpu"
explicit = true

[tool.uv.sources]
torchaudio = [
    { index = "pytorch-cpu", extra = "mps", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cu128", extra = "cuda", marker = "sys_platform != 'darwin'" },
    { index = "pytorch-rocm", extra = "rocm", marker = "sys_platform == 'Linux'" },
    { index = "pytorch-xpu", extra = "xpu", marker = "platform_machine == 'AMD64'" },
]

torchvision = [
    # { index = "pytorch-cpu", extra = "mps", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cpu", marker = "sys_platform != 'darwin'" },
]
torch = [
    { index = "pytorch-cpu", extra = "mps", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cu128", extra = "cuda", marker = "sys_platform != 'darwin'" },
    { index = "pytorch-rocm", extra = "rocm", marker = "sys_platform == 'Linux'" },
    { index = "pytorch-xpu", extra = "xpu", marker = "platform_machine == 'AMD64'" },

]

pytorch-triton-xpu = [
    { index = "pytorch-xpu", extra = "xpu", marker = "platform_machine == 'AMD64'" },

]
"sageattention" = [
    { git = "https://github.com/thu-ml/SageAttention.git", extra = "attention", marker = "sys_platform != 'darwin'" },
]

diffusers = { git = "https://github.com/huggingface/diffusers" }

[[tool.uv.dependency-metadata]]
name          = "flash-attn"
version       = "2.6.3"
requires-dist = ["torch", "einops"]

[[tool.uv.dependency-metadata]]
name          = "sageattention"
version       = "2.2.0"
requires-dist = ["torch"]

[tool.setuptools_scm]
write_to = "_version.py"

[tool.setuptools.packages.find]
where   = ["."]
include = ["nnll*"]
exclude = ["tests*"]

[tool.setuptools.package-data]
nnll = ['nnll/integrity/*.json', "nnll/mir/config/*.json"]

[tool.ruff]
line-length    = 140
include        = ["*.py"]
extend-exclude = ["^tests/.*$", "test.*$"]

[tool.ruff.lint]
ignore = ["E731"]

[tool.pylint]
max-line-length = 140
ignore-paths    = ["^tests/.*$", "test_.*$"]
disable         = ["C0415"]

[tool.ruff.lint.pycodestyle]
max-line-length               = 140
ignore-overlong-task-comments = true

[tool.typos]
files.extend-exclude = ["^tests/.*$", "test.*$"]
default.extend-words = { "ot" = "ot", "convers" = "convers" }
